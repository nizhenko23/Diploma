{"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Load the data\nfrom keras.datasets import cifar10\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()","metadata":{"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d25a24f040e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"],"ename":"ModuleNotFoundError","evalue":"No module named 'keras'","output_type":"error"}]},{"cell_type":"code","source":"#Print the data type of x_train\nprint(type(x_train))\n#Print the data type of y_train\nprint(type(y_train))\n#Print the data type of x_test\nprint(type(x_test))\n#Print the data type of y_test\nprint(type(y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the shape of x_train\nprint('x_train shape:', x_train.shape) #4D array 50,000 rows 32x32 pixel image with depth = 3 visible wave lenghts (RGB)\n#Get the shape of y_train\nprint('y_train shape:', y_train.shape) #2D array 50,000 rows and 1 column\n#Get the shape of x_train\nprint('x_test shape:', x_test.shape) #4D array 10,000 rows 32x32 pixel image with depth = 3 visible wave lenghts (RGB)\n#Get the shape of y_train\nprint('y_test shape:', y_test.shape) #2D array 10,000 rows and 1 column","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Take a look at the first image (at index=0) in the training data set as a numpy array\n#This shows the image as a series of pixel values\nx_train[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show the image as an image instead of a series of pixel values using matplotlib\nimport matplotlib.pyplot as plt\nimg = plt.imshow(x_train[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the label of the image, NOTE: the number 6 = frog\n#0 = airplane\n#1 = automobile\n#2 = bird\n#3 = cat\n#4 = deer\n#5 = dog\n#6 = frog\n#7 = horse\n#8 = ship\n#9 = truck\nprint('The label is:', y_train[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#One-Hot Encoding \n#Convert the labels into a set of 10 numbers to input into the neural network\nfrom keras.utils import to_categorical\ny_train_one_hot = to_categorical(y_train)\ny_test_one_hot = to_categorical(y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print all of the new labels in the training data set\nprint(y_train_one_hot)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print an example of the new labels, NOTE: The label 6 = [0,0,0,0,0,0,1,0,0,0]\nprint('The one hot label is:', y_train_one_hot[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#normalize the pixels in the images to be a value between 0 and 1 , they are normally values between 0 and 255\n#doing this will help the neural network.\nx_train = x_train / 255\nx_test = x_test / 255","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build The CNN\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n\nmodel = Sequential() #Create the architecture\n\n#Convolution layer to extract features from the input image, and create 32 ReLu\n#5x5 convolved features/layers aka feature map.\n#Note:You must input the input shape only in this first layer.\n# number of output channels or convolution filters = 32\n# number of rows in the convolution kernel\n# number of cols in the convolution kernel\n# input shape 32x32 RGB image, so spacially it's 3-Dimensional\n# activation function Rectifier Linear Unit aka (ReLu)\nmodel.add(Conv2D(32, (5, 5), activation='relu', input_shape=(32,32,3))) \n\n\n#Pooling layer with a 2x2 filter to get the max element from the convolved features , \n#this reduces the dimensionality by half e.g. 16x16, aka sub sampling\n#Note: the default for stride is the pool_size\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\n\n#2nd Convolution layer with 64 channels\nmodel.add(Conv2D(64, (5, 5), activation='relu'))\n\n#Adding second Max Pooling layer\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#Flattening, Flattens the input. Does not affect the batch size. \n#(Flattening occurs when you reduce all layers to one background layer), \n#this makes the image a linear array or 1D Array or 1D Vector to \n#feed into or connect with the neural network\nmodel.add(Flatten())\nmodel.add(Dense(1000, activation='relu')) # a layer with 1000 neurons and activation function ReLu\nmodel.add(Dense(10, activation='softmax')) #a layer with 10 output neurons for each label using softmax activation function","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', # loss function used for classes that are greater than 2)\n              optimizer='adam',\n              metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Batch: Total number of training examples present in a single batch\n#Epoch:The number of iterations when an ENTIRE dataset is passed forward and \n#      backward through the neural network only ONCE.\n#Fit: Another word for train\n\n#NOTE: We don't need to use validation_data, so we didn't have to split the data \n#into a validation sets. We just put in 0.2 and this splits the data 20% for us.\nhist = model.fit(x_train, y_train_one_hot, \n           batch_size=256, epochs=10, validation_split=0.3 )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the models accuracy\nmodel.evaluate(x_test, y_test_one_hot)[1]\n#test_loss, test_acc = model.evaluate(test_images, test_labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize the models accuracy\nplt.plot(hist.history['acc'])\nplt.plot(hist.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize the models loss\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load the data\n#from google.colab import files # Use to load data on Google Colab\n#uploaded = files.upload() # Use to load data on Google Colab\nmy_image = plt.imread(\"cat.4014.jpg\") #Read in the image (3, 14, 20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show the uploaded image\nimg = plt.imshow(my_image)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Resize & Show the image\nfrom skimage.transform import resize\nmy_image_resized = resize(my_image, (32,32,3)) #resize the image to 32x32 pixel with depth = 3\nimg = plt.imshow(my_image_resized) #show new image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the probabilities for each class\n#model.predict function is expecting an array, so we will use np.array to make this transformation on the image\nimport numpy as np\nprobabilities = model.predict(np.array( [my_image_resized,] ))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show the probability for each class\nprobabilities","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number_to_class = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\nindex = np.argsort(probabilities[0,:])\nprint(\"Most likely class:\", number_to_class[index[9]], \"-- Probability:\", probabilities[0,index[9]])\nprint(\"Second most likely class:\", number_to_class[index[8]], \"-- Probability:\", probabilities[0,index[8]])\nprint(\"Third most likely class:\", number_to_class[index[7]], \"-- Probability:\", probabilities[0,index[7]])\nprint(\"Fourth most likely class:\", number_to_class[index[6]], \"-- Probability:\", probabilities[0,index[6]])\nprint(\"Fifth most likely class:\", number_to_class[index[5]], \"-- Probability:\", probabilities[0,index[5]])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To save this model \nmodel.save('my_model.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To load this model\nfrom keras.models import load_model\nmodel = load_model('my_model.h5')","metadata":{},"execution_count":null,"outputs":[]}]}